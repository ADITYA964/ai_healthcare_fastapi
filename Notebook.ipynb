{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Extract the Kaggle dataset"
      ],
      "metadata": {
        "id": "X7tpUHskDMZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkhMxMiDMAc0",
        "outputId": "a7b5f7d4-fffa-4c4d-8c9e-a8a53d717bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/Suicide_Detection.csv.zip\n",
            "  inflating: Suicide_Detection.csv   \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/Suicide_Detection.csv.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install packages"
      ],
      "metadata": {
        "id": "Sm1IppFVDtWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas\n",
        "# !pip install numpy\n",
        "# !pip install tensorflow\n",
        "# !pip install tensorflow_hub"
      ],
      "metadata": {
        "id": "KH7at-D-DaaE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Configuration setup"
      ],
      "metadata": {
        "id": "LQcwamUFDzWj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Aditya Configuration ==========\n",
        "\n",
        "class Config:\n",
        "    \n",
        "    # Model folder name containing weights and use it with wandb and 3.5 sec i/p and 3.5 sec o/p.\n",
        "    model_name = \"bert\"  \n",
        "    \n",
        "    \n",
        "    # Current directory as same as repository.\n",
        "    workspace_dir = \"/content/Aditya_workspace_in_GPU/\" \n",
        "    \n",
        "    # Modules related to custom libraries.\n",
        "    module_dir =\"/src\"  \n",
        "    \n",
        "    # Location to save model checkpoints.\n",
        "    checkpoint_dir = (\n",
        "        \"/content/aditya/model_checkpoints/\"          \n",
        "    )\n",
        "    \n",
        "    # Location to retrieve dataset.\n",
        "    data_dir = \"/content/datasets/\"  "
      ],
      "metadata": {
        "id": "OYydUrCxDyDu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Import packages"
      ],
      "metadata": {
        "id": "tIieCsNaD8T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Python libraries ==========\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from keras.utils import to_categorical\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tokenization import *"
      ],
      "metadata": {
        "id": "ZYU1E7uXD6ze"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Define parameters"
      ],
      "metadata": {
        "id": "YdA_cGibEjjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== Model and Learning Parameters ==========\n",
        "\n",
        "output='model.h5'\n",
        "\n",
        "device_name = '/device:GPU:0'\n",
        "\n",
        "m_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2'\n",
        "\n",
        "url = \"https://drive.google.com/uc?id={}\".format(\"1GDYhTNHhat-qa_6fm5OqWTfTUclHFo6Z\")\n",
        "\n",
        "# Initialize seed to any value for reproducing the results of previous model \n",
        "# for fine tuning or designing with new layers or simple training the model.\n",
        "SEED = 1291       \n",
        "\n",
        "# Select the batch size which makes max usage of memory for\n",
        "# passing data samples to the model for training purpose.\n",
        "BATCH_SIZE = 32    \n",
        "\n",
        "# Assign the total number of loops for training model over whole dataset.\n",
        "N_EPOCHS = 10    \n",
        "\n",
        "# Early stop the model from training till atmost 300 epochs.\n",
        "EARLY_STOP_EPOCHS = 5 \n",
        "\n",
        "# Select optimum set of weights for the model after each \n",
        "# batch so that the model succeeds in reaching the objective.\n",
        "LEARNING_RATE = 0.001    "
      ],
      "metadata": {
        "id": "EJWfrLUoEYve"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. User defined functions\n"
      ],
      "metadata": {
        "id": "7stjoCHEJBHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_available_gpus():\n",
        "    local_device_protos = device_lib.list_local_devices()\n",
        "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
        "    \n",
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    all_tokens = []\n",
        "    all_masks = []\n",
        "    all_segments = []\n",
        "    \n",
        "    for text in texts:\n",
        "        text = tokenizer.tokenize(text)\n",
        "        \n",
        "        text = text[:max_len-2]\n",
        "        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n",
        "        pad_len = max_len-len(input_sequence)\n",
        "        \n",
        "        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n",
        "        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n",
        "        segment_ids = [0] * max_len\n",
        "        \n",
        "        all_tokens.append(tokens)\n",
        "        all_masks.append(pad_masks)\n",
        "        all_segments.append(segment_ids)\n",
        "        \n",
        "    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n",
        "\n",
        "\n",
        "def build_model(bert_layer, max_len=512):\n",
        "  \n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    \n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    \n",
        "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    out = tf.keras.layers.Dense(2, activation='softmax')(lay)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model    "
      ],
      "metadata": {
        "id": "-lgRPRSRJEHU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Load dataset"
      ],
      "metadata": {
        "id": "XaSeNmDzJQiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/Suicide_Detection.csv\")\n",
        "df = df.drop(['Unnamed: 0'], axis=1)"
      ],
      "metadata": {
        "id": "8W4T09TWMhmk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Configure BERT"
      ],
      "metadata": {
        "id": "aqDUiyPlJj3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = hub.KerasLayer(m_url, trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "metadata": {
        "id": "Au2WUAAAJUEh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_available_gpus()"
      ],
      "metadata": {
        "id": "om_iU3dbPxFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Prepare dataset for training"
      ],
      "metadata": {
        "id": "wPgP1UjDJpix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 250\n",
        "with tf.device(device_name):\n",
        "\n",
        "  train_input = bert_encode(df.text.values[:10000], tokenizer, max_len=max_len)\n",
        "  test_input = bert_encode(df.text.values[10000:15000], tokenizer, max_len=max_len)"
      ],
      "metadata": {
        "id": "JnEyqQbvNIES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = preprocessing.LabelEncoder()\n",
        "train_y = label.fit_transform(df['class'][:10000])\n",
        "train_y = to_categorical(train_y)\n",
        "\n",
        "test_y = label.fit_transform(df['class'][10000:15000])\n",
        "test_y = to_categorical(test_y)\n",
        "print(train_y[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWj7Z1-RYCtA",
        "outputId": "678cf993-0a22-4c61-e4f6-2d4ae185fe7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Initialize BERT"
      ],
      "metadata": {
        "id": "0Ut5DaU8J3Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(bert_layer, max_len=max_len)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3tOse3ZKfUF",
        "outputId": "0a980052-a466-4bce-970c-a99ce9b455e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 250)]        0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 250, 768)]                'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  (None, 768)         0           ['keras_layer[0][1]']            \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64)           49216       ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64)           0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           2080        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32)           0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            66          ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,533,603\n",
            "Trainable params: 51,362\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Training the model"
      ],
      "metadata": {
        "id": "ky7g4VOxJ8Di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, verbose=1)\n",
        "\n",
        "with tf.device(device_name):\n",
        "\n",
        "  tf.config.experimental_run_functions_eagerly(True)\n",
        "  \n",
        "  train_sh = model.fit(\n",
        "    train_input, train_y,\n",
        "    validation_data=[test_input,test_y],\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint, earlystopping],\n",
        "    batch_size=16,\n",
        "    verbose=1\n",
        "   )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiGYTPkZNuK9",
        "outputId": "8419dfd9-ee36-4265-9b3e-f8c08c9cd7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-ca89eca48484>:5: experimental_run_functions_eagerly (from tensorflow.python.eager.polymorphic_function.quarantine) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.run_functions_eagerly` instead of the experimental version.\n",
            "/usr/local/lib/python3.9/dist-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.3033 - accuracy: 0.8811\n",
            "Epoch 1: val_accuracy improved from -inf to 0.91080, saving model to model.h5\n",
            "625/625 [==============================] - 702s 1s/step - loss: 0.3033 - accuracy: 0.8811 - val_loss: 0.2312 - val_accuracy: 0.9108\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2381 - accuracy: 0.9097\n",
            "Epoch 2: val_accuracy improved from 0.91080 to 0.92040, saving model to model.h5\n",
            "625/625 [==============================] - 653s 1s/step - loss: 0.2381 - accuracy: 0.9097 - val_loss: 0.2045 - val_accuracy: 0.9204\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.9178\n",
            "Epoch 3: val_accuracy improved from 0.92040 to 0.92220, saving model to model.h5\n",
            "625/625 [==============================] - 690s 1s/step - loss: 0.2221 - accuracy: 0.9178 - val_loss: 0.2044 - val_accuracy: 0.9222\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2079 - accuracy: 0.9224\n",
            "Epoch 4: val_accuracy improved from 0.92220 to 0.92540, saving model to model.h5\n",
            "625/625 [==============================] - 691s 1s/step - loss: 0.2079 - accuracy: 0.9224 - val_loss: 0.1951 - val_accuracy: 0.9254\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1956 - accuracy: 0.9288\n",
            "Epoch 5: val_accuracy improved from 0.92540 to 0.92740, saving model to model.h5\n",
            "625/625 [==============================] - 691s 1s/step - loss: 0.1956 - accuracy: 0.9288 - val_loss: 0.1881 - val_accuracy: 0.9274\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9301\n",
            "Epoch 6: val_accuracy did not improve from 0.92740\n",
            "625/625 [==============================] - 690s 1s/step - loss: 0.1890 - accuracy: 0.9301 - val_loss: 0.1935 - val_accuracy: 0.9244\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9296\n",
            "Epoch 7: val_accuracy did not improve from 0.92740\n",
            "625/625 [==============================] - 690s 1s/step - loss: 0.1867 - accuracy: 0.9296 - val_loss: 0.1867 - val_accuracy: 0.9268\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1771 - accuracy: 0.9345\n",
            "Epoch 8: val_accuracy did not improve from 0.92740\n",
            "625/625 [==============================] - 651s 1s/step - loss: 0.1771 - accuracy: 0.9345 - val_loss: 0.1866 - val_accuracy: 0.9274\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9345\n",
            "Epoch 9: val_accuracy did not improve from 0.92740\n",
            "625/625 [==============================] - 688s 1s/step - loss: 0.1757 - accuracy: 0.9345 - val_loss: 0.1955 - val_accuracy: 0.9266\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9387\n",
            "Epoch 10: val_accuracy improved from 0.92740 to 0.93020, saving model to model.h5\n",
            "625/625 [==============================] - 691s 1s/step - loss: 0.1682 - accuracy: 0.9387 - val_loss: 0.1883 - val_accuracy: 0.9302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Inference test"
      ],
      "metadata": {
        "id": "iwXIu5nsL65Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/model_new.h5\")"
      ],
      "metadata": {
        "id": "fJ-z_8tdKPNu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def outcome(test):\n",
        "  \n",
        "  suicide=0\n",
        "  if test[0][1]>0.5:\n",
        "      suicide = 1\n",
        "\n",
        "  if suicide==1:\n",
        "    result=\"Suicide\"\n",
        "  else:\n",
        "    result=\"No suicide\"\n",
        "  return result  "
      ],
      "metadata": {
        "id": "ZJ7W1bHGLmk4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = [\"Mood Diary Input | Day 1 = Today, I felt good in the morning; everything was good,but in the evening\",\n",
        "        \", it rained, and as a result, I got stuck in traffic. My life sucks;I should end it; I should kill myself.\"]\n",
        "\n",
        "\n",
        "text_2 = ['''Mood Diary Input | Day 1 = \"Today I felt good in the morning, everything was good, but in the evening, it rained, and as a result, I got stuck in the traffic; my life sucks\"''']        "
      ],
      "metadata": {
        "id": "byCja1DgKpt1"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_1 = bert_encode([text_1[0]+text_1[1]],tokenizer,max_len=max_len)"
      ],
      "metadata": {
        "id": "idqxTwZrNyZX"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome(model.predict(test_1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "U1oXPrlsLdf6",
        "outputId": "f44e32ba-7f29-4544-9f8d-6cec6b0f0eee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Suicide'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_2= bert_encode(text_2,tokenizer,max_len=max_len)"
      ],
      "metadata": {
        "id": "yh73mImnzEvJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome(model.predict(test_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "M1pmgtgC4KNK",
        "outputId": "c9afb808-9c7d-437d-e455-1cccca8cb827"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No suicide'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}